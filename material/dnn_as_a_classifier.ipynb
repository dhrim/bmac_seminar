{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dnn_as_a_classifier.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCKgjM9-xygH",
        "colab_type": "text"
      },
      "source": [
        "# 분류기로서의 DNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etOyOaq6xxHv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmBdLDqix7Jh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_square_data(all_low, all_high, square_low, square_high, zero_count, one_count):\n",
        "\n",
        "  x1 = np.random.rand(one_count)\n",
        "  x1 = x1*(square_high-square_low) + square_low\n",
        "\n",
        "  x0 = np.random.rand(zero_count*100)\n",
        "  x0 = x0[ (x0<square_low) | (square_high<x0) ]\n",
        "  x0 = x0[:zero_count]\n",
        "\n",
        "  x = np.append(x1, x0)\n",
        "\n",
        "  plt.hist(x)\n",
        "  plt.xlim(0, 1)\n",
        "  plt.show()\n",
        "\n",
        "  # 범위 안의 것을 1, 범위 밖의 것을 0으로 하고\n",
        "  all_data = np.ones((len(x),2))\n",
        "  all_data[:,0] = x\n",
        "\n",
        "  all_data[:len(x1),1] = 1\n",
        "  all_data[len(x1):,1] = 0\n",
        "\n",
        "  # 섞는다\n",
        "  np.random.shuffle(all_data)\n",
        "\n",
        "  # x, y로 분리하고\n",
        "  x = all_data[:,0]\n",
        "  y = all_data[:,1]\n",
        "\n",
        "  plt.xlim(0, 1)\n",
        "\n",
        "  plt.scatter(x, y)\n",
        "\n",
        "  return x, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJ5rov-EyCN4",
        "colab_type": "text"
      },
      "source": [
        "# 네모 함수의 학습\n",
        "\n",
        "특정 영역은 1, 이외의 영역은 0을 출력\n",
        "\n",
        "1개의 출력 노드를 갖는다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10wyiaaEx_Eo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "outputId": "aae51a38-1cbf-401a-dc61-e3c173cb07d2"
      },
      "source": [
        "all_low = 0\n",
        "all_high = 1\n",
        "square_low = 0.5\n",
        "square_high = 0.6\n",
        "zero_count = 10000\n",
        "one_count = 10000\n",
        "\n",
        "train_x, train_y = build_square_data(all_low, all_high, square_low, square_high, zero_count, one_count)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAD8CAYAAACGsIhGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLCRJXYaFJKnr/wCQibZu+kxfxgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nr6bKR78AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7fuP8OIyJBP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "34f3af8a-93c2-416a-b268-7fd471875d65"
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "\n",
        "model = keras.Sequential()\n",
        "model.add(Dense(10, activation='relu', input_shape=(1,)))\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "\n",
        "\n",
        "\n",
        "model.compile(optimizer=\"SGD\", loss=\"mse\")\n",
        "model = build_model()\n",
        "model.fit(train_x, train_y, epochs=100, verbose=1, batch_size=32, validation_split=0.1)\n",
        "\n",
        "x_ = np.arange(all_low, all_high, 0.01)\n",
        "y_ = model.predict(x_)\n",
        "plt.scatter(x_, y_)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_8 (Dense)              (None, 10)                20        \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 10)                110       \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 10)                110       \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 251\n",
            "Trainable params: 251\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 18000 samples, validate on 2000 samples\n",
            "Epoch 1/100\n",
            "18000/18000 [==============================] - 1s 41us/sample - loss: 0.2462 - val_loss: 0.2403\n",
            "Epoch 2/100\n",
            "18000/18000 [==============================] - 1s 32us/sample - loss: 0.2290 - val_loss: 0.2226\n",
            "Epoch 3/100\n",
            "18000/18000 [==============================] - 1s 33us/sample - loss: 0.2038 - val_loss: 0.1879\n",
            "Epoch 4/100\n",
            "18000/18000 [==============================] - 1s 33us/sample - loss: 0.1674 - val_loss: 0.1459\n",
            "Epoch 5/100\n",
            "18000/18000 [==============================] - 1s 33us/sample - loss: 0.1214 - val_loss: 0.0957\n",
            "Epoch 6/100\n",
            "18000/18000 [==============================] - 1s 34us/sample - loss: 0.0794 - val_loss: 0.0633\n",
            "Epoch 7/100\n",
            "18000/18000 [==============================] - 1s 34us/sample - loss: 0.0575 - val_loss: 0.0481\n",
            "Epoch 8/100\n",
            "18000/18000 [==============================] - 1s 33us/sample - loss: 0.0459 - val_loss: 0.0398\n",
            "Epoch 9/100\n",
            "18000/18000 [==============================] - 1s 32us/sample - loss: 0.0384 - val_loss: 0.0343\n",
            "Epoch 10/100\n",
            "18000/18000 [==============================] - 1s 33us/sample - loss: 0.0332 - val_loss: 0.0300\n",
            "Epoch 11/100\n",
            "18000/18000 [==============================] - 1s 34us/sample - loss: 0.0293 - val_loss: 0.0270\n",
            "Epoch 12/100\n",
            "18000/18000 [==============================] - 1s 33us/sample - loss: 0.0264 - val_loss: 0.0245\n",
            "Epoch 13/100\n",
            "18000/18000 [==============================] - 1s 33us/sample - loss: 0.0243 - val_loss: 0.0225\n",
            "Epoch 14/100\n",
            "18000/18000 [==============================] - 1s 35us/sample - loss: 0.0227 - val_loss: 0.0225\n",
            "Epoch 15/100\n",
            "18000/18000 [==============================] - 1s 36us/sample - loss: 0.0214 - val_loss: 0.0204\n",
            "Epoch 16/100\n",
            "18000/18000 [==============================] - 1s 32us/sample - loss: 0.0206 - val_loss: 0.0195\n",
            "Epoch 17/100\n",
            "18000/18000 [==============================] - 1s 33us/sample - loss: 0.0198 - val_loss: 0.0196\n",
            "Epoch 18/100\n",
            "18000/18000 [==============================] - 1s 33us/sample - loss: 0.0193 - val_loss: 0.0185\n",
            "Epoch 19/100\n",
            "18000/18000 [==============================] - 1s 33us/sample - loss: 0.0186 - val_loss: 0.0185\n",
            "Epoch 20/100\n",
            "18000/18000 [==============================] - 1s 33us/sample - loss: 0.0182 - val_loss: 0.0194\n",
            "Epoch 21/100\n",
            "18000/18000 [==============================] - 1s 35us/sample - loss: 0.0177 - val_loss: 0.0170\n",
            "Epoch 22/100\n",
            "18000/18000 [==============================] - 1s 33us/sample - loss: 0.0173 - val_loss: 0.0165\n",
            "Epoch 23/100\n",
            "18000/18000 [==============================] - 1s 33us/sample - loss: 0.0168 - val_loss: 0.0158\n",
            "Epoch 24/100\n",
            "18000/18000 [==============================] - 1s 33us/sample - loss: 0.0163 - val_loss: 0.0159\n",
            "Epoch 25/100\n",
            "18000/18000 [==============================] - 1s 34us/sample - loss: 0.0157 - val_loss: 0.0149\n",
            "Epoch 26/100\n",
            "18000/18000 [==============================] - 1s 33us/sample - loss: 0.0152 - val_loss: 0.0144\n",
            "Epoch 27/100\n",
            "18000/18000 [==============================] - 1s 33us/sample - loss: 0.0146 - val_loss: 0.0144\n",
            "Epoch 28/100\n",
            "18000/18000 [==============================] - 1s 34us/sample - loss: 0.0142 - val_loss: 0.0131\n",
            "Epoch 29/100\n",
            "18000/18000 [==============================] - 1s 32us/sample - loss: 0.0137 - val_loss: 0.0129\n",
            "Epoch 30/100\n",
            "18000/18000 [==============================] - 1s 32us/sample - loss: 0.0131 - val_loss: 0.0123\n",
            "Epoch 31/100\n",
            "18000/18000 [==============================] - 1s 33us/sample - loss: 0.0126 - val_loss: 0.0119\n",
            "Epoch 32/100\n",
            "18000/18000 [==============================] - 1s 35us/sample - loss: 0.0121 - val_loss: 0.0113\n",
            "Epoch 33/100\n",
            "18000/18000 [==============================] - 1s 34us/sample - loss: 0.0117 - val_loss: 0.0110\n",
            "Epoch 34/100\n",
            "18000/18000 [==============================] - 1s 33us/sample - loss: 0.0115 - val_loss: 0.0111\n",
            "Epoch 35/100\n",
            "18000/18000 [==============================] - 1s 33us/sample - loss: 0.0112 - val_loss: 0.0102\n",
            "Epoch 36/100\n",
            "18000/18000 [==============================] - 1s 32us/sample - loss: 0.0109 - val_loss: 0.0101\n",
            "Epoch 37/100\n",
            "18000/18000 [==============================] - 1s 33us/sample - loss: 0.0105 - val_loss: 0.0096\n",
            "Epoch 38/100\n",
            "18000/18000 [==============================] - 1s 32us/sample - loss: 0.0104 - val_loss: 0.0099\n",
            "Epoch 39/100\n",
            "18000/18000 [==============================] - 1s 32us/sample - loss: 0.0101 - val_loss: 0.0092\n",
            "Epoch 40/100\n",
            "18000/18000 [==============================] - 1s 33us/sample - loss: 0.0098 - val_loss: 0.0091\n",
            "Epoch 41/100\n",
            "18000/18000 [==============================] - 1s 32us/sample - loss: 0.0097 - val_loss: 0.0168\n",
            "Epoch 42/100\n",
            "18000/18000 [==============================] - 1s 33us/sample - loss: 0.0095 - val_loss: 0.0087\n",
            "Epoch 43/100\n",
            "18000/18000 [==============================] - 1s 34us/sample - loss: 0.0093 - val_loss: 0.0084\n",
            "Epoch 44/100\n",
            "18000/18000 [==============================] - 1s 34us/sample - loss: 0.0090 - val_loss: 0.0082\n",
            "Epoch 45/100\n",
            "18000/18000 [==============================] - 1s 33us/sample - loss: 0.0091 - val_loss: 0.0081\n",
            "Epoch 46/100\n",
            "18000/18000 [==============================] - 1s 32us/sample - loss: 0.0088 - val_loss: 0.0138\n",
            "Epoch 47/100\n",
            "18000/18000 [==============================] - 1s 32us/sample - loss: 0.0086 - val_loss: 0.0081\n",
            "Epoch 48/100\n",
            "18000/18000 [==============================] - 1s 34us/sample - loss: 0.0085 - val_loss: 0.0077\n",
            "Epoch 49/100\n",
            "18000/18000 [==============================] - 1s 32us/sample - loss: 0.0085 - val_loss: 0.0073\n",
            "Epoch 50/100\n",
            "18000/18000 [==============================] - 1s 33us/sample - loss: 0.0082 - val_loss: 0.0079\n",
            "Epoch 51/100\n",
            "18000/18000 [==============================] - 1s 32us/sample - loss: 0.0081 - val_loss: 0.0096\n",
            "Epoch 52/100\n",
            "18000/18000 [==============================] - 1s 33us/sample - loss: 0.0080 - val_loss: 0.0088\n",
            "Epoch 53/100\n",
            "18000/18000 [==============================] - 1s 32us/sample - loss: 0.0079 - val_loss: 0.0070\n",
            "Epoch 54/100\n",
            "18000/18000 [==============================] - 1s 36us/sample - loss: 0.0078 - val_loss: 0.0068\n",
            "Epoch 55/100\n",
            "18000/18000 [==============================] - 1s 33us/sample - loss: 0.0077 - val_loss: 0.0085\n",
            "Epoch 56/100\n",
            "18000/18000 [==============================] - 1s 32us/sample - loss: 0.0076 - val_loss: 0.0065\n",
            "Epoch 57/100\n",
            "18000/18000 [==============================] - 1s 33us/sample - loss: 0.0075 - val_loss: 0.0067\n",
            "Epoch 58/100\n",
            "18000/18000 [==============================] - 1s 34us/sample - loss: 0.0075 - val_loss: 0.0067\n",
            "Epoch 59/100\n",
            "18000/18000 [==============================] - 1s 32us/sample - loss: 0.0073 - val_loss: 0.0063\n",
            "Epoch 60/100\n",
            "18000/18000 [==============================] - 1s 33us/sample - loss: 0.0072 - val_loss: 0.0107\n",
            "Epoch 61/100\n",
            "18000/18000 [==============================] - 1s 33us/sample - loss: 0.0070 - val_loss: 0.0072\n",
            "Epoch 62/100\n",
            "18000/18000 [==============================] - 1s 33us/sample - loss: 0.0071 - val_loss: 0.0071\n",
            "Epoch 63/100\n",
            "18000/18000 [==============================] - 1s 33us/sample - loss: 0.0071 - val_loss: 0.0060\n",
            "Epoch 64/100\n",
            "18000/18000 [==============================] - 1s 33us/sample - loss: 0.0069 - val_loss: 0.0065\n",
            "Epoch 65/100\n",
            "18000/18000 [==============================] - 1s 34us/sample - loss: 0.0068 - val_loss: 0.0059\n",
            "Epoch 66/100\n",
            "18000/18000 [==============================] - 1s 34us/sample - loss: 0.0067 - val_loss: 0.0059\n",
            "Epoch 67/100\n",
            "18000/18000 [==============================] - 1s 35us/sample - loss: 0.0067 - val_loss: 0.0057\n",
            "Epoch 68/100\n",
            "18000/18000 [==============================] - 1s 35us/sample - loss: 0.0066 - val_loss: 0.0063\n",
            "Epoch 69/100\n",
            "18000/18000 [==============================] - 1s 34us/sample - loss: 0.0066 - val_loss: 0.0054\n",
            "Epoch 70/100\n",
            "18000/18000 [==============================] - 1s 34us/sample - loss: 0.0065 - val_loss: 0.0053\n",
            "Epoch 71/100\n",
            "18000/18000 [==============================] - 1s 34us/sample - loss: 0.0064 - val_loss: 0.0163\n",
            "Epoch 72/100\n",
            "18000/18000 [==============================] - 1s 33us/sample - loss: 0.0065 - val_loss: 0.0064\n",
            "Epoch 73/100\n",
            "18000/18000 [==============================] - 1s 33us/sample - loss: 0.0063 - val_loss: 0.0102\n",
            "Epoch 74/100\n",
            "18000/18000 [==============================] - 1s 33us/sample - loss: 0.0064 - val_loss: 0.0052\n",
            "Epoch 75/100\n",
            "18000/18000 [==============================] - 1s 34us/sample - loss: 0.0063 - val_loss: 0.0071\n",
            "Epoch 76/100\n",
            "18000/18000 [==============================] - 1s 35us/sample - loss: 0.0061 - val_loss: 0.0111\n",
            "Epoch 77/100\n",
            "18000/18000 [==============================] - 1s 32us/sample - loss: 0.0062 - val_loss: 0.0049\n",
            "Epoch 78/100\n",
            "18000/18000 [==============================] - 1s 33us/sample - loss: 0.0061 - val_loss: 0.0052\n",
            "Epoch 79/100\n",
            "18000/18000 [==============================] - 1s 32us/sample - loss: 0.0061 - val_loss: 0.0051\n",
            "Epoch 80/100\n",
            "18000/18000 [==============================] - 1s 32us/sample - loss: 0.0060 - val_loss: 0.0053\n",
            "Epoch 81/100\n",
            "18000/18000 [==============================] - 1s 33us/sample - loss: 0.0060 - val_loss: 0.0060\n",
            "Epoch 82/100\n",
            "18000/18000 [==============================] - 1s 33us/sample - loss: 0.0059 - val_loss: 0.0116\n",
            "Epoch 83/100\n",
            "18000/18000 [==============================] - 1s 33us/sample - loss: 0.0061 - val_loss: 0.0048\n",
            "Epoch 84/100\n",
            "18000/18000 [==============================] - 1s 34us/sample - loss: 0.0058 - val_loss: 0.0046\n",
            "Epoch 85/100\n",
            "18000/18000 [==============================] - 1s 33us/sample - loss: 0.0059 - val_loss: 0.0095\n",
            "Epoch 86/100\n",
            "18000/18000 [==============================] - 1s 33us/sample - loss: 0.0057 - val_loss: 0.0049\n",
            "Epoch 87/100\n",
            "18000/18000 [==============================] - 1s 34us/sample - loss: 0.0058 - val_loss: 0.0046\n",
            "Epoch 88/100\n",
            "18000/18000 [==============================] - 1s 33us/sample - loss: 0.0057 - val_loss: 0.0045\n",
            "Epoch 89/100\n",
            "18000/18000 [==============================] - 1s 34us/sample - loss: 0.0057 - val_loss: 0.0044\n",
            "Epoch 90/100\n",
            "18000/18000 [==============================] - 1s 34us/sample - loss: 0.0056 - val_loss: 0.0044\n",
            "Epoch 91/100\n",
            "18000/18000 [==============================] - 1s 33us/sample - loss: 0.0056 - val_loss: 0.0047\n",
            "Epoch 92/100\n",
            "18000/18000 [==============================] - 1s 34us/sample - loss: 0.0058 - val_loss: 0.0045\n",
            "Epoch 93/100\n",
            "18000/18000 [==============================] - 1s 33us/sample - loss: 0.0056 - val_loss: 0.0077\n",
            "Epoch 94/100\n",
            "18000/18000 [==============================] - 1s 34us/sample - loss: 0.0054 - val_loss: 0.0047\n",
            "Epoch 95/100\n",
            "18000/18000 [==============================] - 1s 34us/sample - loss: 0.0055 - val_loss: 0.0043\n",
            "Epoch 96/100\n",
            "18000/18000 [==============================] - 1s 33us/sample - loss: 0.0055 - val_loss: 0.0042\n",
            "Epoch 97/100\n",
            "18000/18000 [==============================] - 1s 33us/sample - loss: 0.0056 - val_loss: 0.0043\n",
            "Epoch 98/100\n",
            "18000/18000 [==============================] - 1s 33us/sample - loss: 0.0053 - val_loss: 0.0041\n",
            "Epoch 99/100\n",
            "18000/18000 [==============================] - 1s 33us/sample - loss: 0.0052 - val_loss: 0.0066\n",
            "Epoch 100/100\n",
            "18000/18000 [==============================] - 1s 34us/sample - loss: 0.0053 - val_loss: 0.0225\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f71a5d9a550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nA7xmBV5hkROIAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKbC_Lnyyavy",
        "colab_type": "text"
      },
      "source": [
        "특정 패턴인 경우 1, 다른 경우인 경우 0으로 분류한다.\n",
        "\n",
        "출력된 값이 0.5보다 크면 1로, 0.5보다 작으면 0으로 간주한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjdw0YWYzOzf",
        "colab_type": "text"
      },
      "source": [
        "# 클래스 2개, 출력노드 2개\n",
        "\n",
        "분류 카테고리의 개수 대로 출력노드를 갖고, one-hot-encoding된 값을 출력하면, 변별력이 커진다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LM2kPa60My1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "outputId": "4ec48c69-9409-4a5f-c720-69d30cd39e6f"
      },
      "source": [
        "all_low = 0\n",
        "all_high = 1\n",
        "square_low = 0.5\n",
        "square_high = 0.6\n",
        "zero_count = 10000\n",
        "one_count = 10000\n",
        "\n",
        "train_x, train_y = build_square_data(all_low, all_high, square_low, square_high, zero_count, one_count)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAD8CAYAAACGsIhGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAADn1JREFUeJzt3X+o3Xd9x/Hny2SxiLUOc2WSH6bD\nVAw6aD10HcJ01I20QvKHzqVQ1FEMKpUxRchwdFIZ6GRuk2XTuBWtoLX2D7nQSP7QSkGM5JbOzqRE\n7mLX3Cg01hoGRWvce3+c43K8Jr3fnHt+3NzP8wGh53zP557z7ofkmXPP95ybVBWSpPXvBbMeQJI0\nHQZfkhph8CWpEQZfkhph8CWpEQZfkhph8CWpEQZfkhph8CWpERtn9cCbN2+uHTt2zOrhJemK9Mgj\nj/y4quZG+dqZBX/Hjh0sLCzM6uEl6YqU5L9H/Vpf0pGkRhh8SWqEwZekRhh8SWqEwZekRhh8SWqE\nwZekRqwY/CT3JHkqyfcucXuSfCrJYpLHktww/jElSavV5YNXnwP+Gbj3ErffAuwc/Pp94F8H/5Wu\nKDsOPDjrES7piY+9ZdYjaB1Y8Rl+VT0M/OR5luwF7q2+o8BLk7xiXANK07CWYw9rfz5dGcbxGv4W\n4PTQ9aXBMUnSGjLVk7ZJ9idZSLJw9uzZaT60JDVvHME/A2wbur51cOw3VNWhqupVVW9ubqQf9iZJ\nGtE4gj8PvGPwbp2bgHNV9aMx3K8kaYy6vC3zS8C3gVcnWUpyR5L3JHnPYMlh4BSwCHwWeN/EppUm\nZK2/C2atz6crQ6pqJg/c6/XKn4cvSZcnySNV1Rvla/2krSQ1wuBLUiMMviQ1wuBLUiMMviQ1wuBL\nUiMMviQ1wuBLUiMMviQ1wuBLUiMMviQ1wuBLUiMMviQ1wuBLUiMMviQ1wuBLUiMMviQ1wuBLUiMM\nviQ1wuBLUiMMviQ1wuBLUiMMviQ1wuBLUiMMviQ1wuBLUiMMviQ1wuBLUiMMviQ1wuBLUiM6BT/J\n7iQnkywmOXCR27cneSjJo0keS3Lr+EeVJK3GisFPsgE4CNwC7AJuS7Jr2bK/Bu6vquuBfcC/jHtQ\nSdLqdHmGfyOwWFWnquo54D5g77I1BbxkcPka4IfjG1GSNA5dgr8FOD10fWlwbNhHgNuTLAGHgfdf\n7I6S7E+ykGTh7NmzI4wrSRrVuE7a3gZ8rqq2ArcCX0jyG/ddVYeqqldVvbm5uTE9tCSpiy7BPwNs\nG7q+dXBs2B3A/QBV9W3gKmDzOAaUJI1Hl+AfA3YmuTbJJvonZeeXrXkSuBkgyWvoB9/XbCRpDVkx\n+FV1HrgTOAI8Tv/dOMeT3J1kz2DZB4F3J/ku8CXgXVVVkxpaknT5NnZZVFWH6Z+MHT5219DlE8Ab\nxjuaJGmc/KStJDXC4EtSIwy+JDXC4EtSIwy+JDXC4EtSIwy+JDXC4EtSIwy+JDXC4EtSIwy+JDXC\n4EtSIwy+JDXC4EtSIwy+JDXC4EtSIwy+JDXC4EtSIwy+JDXC4EtSIwy+JDXC4EtSIwy+JDXC4EtS\nIwy+JDXC4EtSIwy+JDXC4EtSIwy+JDWiU/CT7E5yMslikgOXWPP2JCeSHE/yxfGOKUlarY0rLUiy\nATgI/DGwBBxLMl9VJ4bW7AT+CnhDVT2T5OWTGliSNJouz/BvBBar6lRVPQfcB+xdtubdwMGqegag\nqp4a75iSpNXqEvwtwOmh60uDY8OuA65L8q0kR5PsHteAkqTxWPElncu4n53Am4CtwMNJXldVPx1e\nlGQ/sB9g+/btY3poSVIXXZ7hnwG2DV3fOjg2bAmYr6pfVNUPgO/T/wvg11TVoarqVVVvbm5u1Jkl\nSSPoEvxjwM4k1ybZBOwD5pet+Sr9Z/ck2Uz/JZ5TY5xTkrRKKwa/qs4DdwJHgMeB+6vqeJK7k+wZ\nLDsCPJ3kBPAQ8KGqenpSQ0uSLl+qaiYP3Ov1amFhYSaPLUlXqiSPVFVvlK/1k7aS1AiDL0mNMPiS\n1AiDL0mNMPiS1AiDL0mNMPiS1AiDL0mNMPiS1AiDL0mNMPiS1AiDL0mNMPiS1AiDL0mNMPiS1AiD\nL0mNMPiS1AiDL0mNMPiS1AiDL0mNMPiS1AiDL0mNMPiS1AiDL0mNMPiS1AiDL0mNMPiS1AiDL0mN\nMPiS1AiDL0mN6BT8JLuTnEyymOTA86x7a5JK0hvfiJKkcVgx+Ek2AAeBW4BdwG1Jdl1k3dXAXwDf\nGfeQkqTV6/IM/0ZgsapOVdVzwH3A3ous+yjwceBnY5xPkjQmXYK/BTg9dH1pcOz/JbkB2FZVDz7f\nHSXZn2QhycLZs2cve1hJ0uhWfdI2yQuATwIfXGltVR2qql5V9ebm5lb70JKky9Al+GeAbUPXtw6O\n/crVwGuBbyZ5ArgJmPfErSStLV2CfwzYmeTaJJuAfcD8r26sqnNVtbmqdlTVDuAosKeqFiYysSRp\nJCsGv6rOA3cCR4DHgfur6niSu5PsmfSAkqTx2NhlUVUdBg4vO3bXJda+afVjSZLGzU/aSlIjDL4k\nNcLgS1IjDL4kNcLgS1IjDL4kNcLgS1IjDL4kNcLgS1IjDL4kNcLgS1IjDL4kNcLgS1IjDL4kNcLg\nS1IjDL4kNcLgS1IjDL4kNcLgS1IjDL4kNcLgS1IjDL4kNcLgS1IjDL4kNcLgS1IjDL4kNcLgS1Ij\nDL4kNcLgS1IjOgU/ye4kJ5MsJjlwkds/kOREkseSfD3JK8c/qiRpNVYMfpINwEHgFmAXcFuSXcuW\nPQr0qur3gAeAvxv3oJKk1enyDP9GYLGqTlXVc8B9wN7hBVX1UFU9O7h6FNg63jElSavVJfhbgNND\n15cGxy7lDuBrqxlKkjR+G8d5Z0luB3rAGy9x+35gP8D27dvH+dCSpBV0eYZ/Btg2dH3r4NivSfJm\n4MPAnqr6+cXuqKoOVVWvqnpzc3OjzCtJGlGX4B8Ddia5NskmYB8wP7wgyfXAZ+jH/qnxjylJWq0V\ng19V54E7gSPA48D9VXU8yd1J9gyWfQJ4MfCVJP+RZP4SdydJmpFOr+FX1WHg8LJjdw1dfvOY55Ik\njZmftJWkRhh8SWqEwZekRhh8SWqEwZekRhh8SWqEwZekRhh8SWqEwZekRhh8SWqEwZekRhh8SWqE\nwZekRhh8SWqEwZekRhh8SWqEwZekRhh8SWqEwZekRhh8SWqEwZekRhh8SWqEwZekRhh8SWqEwZek\nRhh8SWqEwZekRhh8SWqEwZekRhh8SWrExi6LkuwG/gnYAPxbVX1s2e0vBO4FXg88DfxZVT3xfPf5\nn2fOsePAg6PMLE3NEx97y9Qf0z8Xej6bfudVrx/1a1d8hp9kA3AQuAXYBdyWZNeyZXcAz1TVq4B/\nAD4+6kDSWjLt+Bp7TVKXl3RuBBar6lRVPQfcB+xdtmYv8PnB5QeAm5NkfGNKklarS/C3AKeHri8N\njl10TVWdB84BL1t+R0n2J1lIsvDLZ8+NNrEkaSRTPWlbVYeqqldVvQ0vumaaDy1JzesS/DPAtqHr\nWwfHLromyUbgGvonbyVJa0SX4B8Ddia5NskmYB8wv2zNPPDOweW3Ad+oqhrfmNJsTPtdOrN4V5Da\nkS5dTnIr8I/035Z5T1X9bZK7gYWqmk9yFfAF4HrgJ8C+qjr1fPfZ6/VqYWFh1f8DktSSJI9UVW+U\nr+30PvyqOgwcXnbsrqHLPwP+dJQBJEnT4SdtJakRBl+SGmHwJakRBl+SGmHwJakRBl+SGmHwJakR\nnT54NZEHTv4HODmTB197NgM/nvUQa4R7cYF7cYF7ccGrq+rqUb6w0wevJuTkqJ8WW2+SLLgXfe7F\nBe7FBe7FBUlG/hEFvqQjSY0w+JLUiFkG/9AMH3utcS8ucC8ucC8ucC8uGHkvZnbSVpI0Xb6kI0mN\nmHjwk+xOcjLJYpIDF7n9hUm+PLj9O0l2THqmWemwFx9IciLJY0m+nuSVs5hzGlbai6F1b01SSdbt\nOzS67EWStw9+bxxP8sVpzzgtHf6MbE/yUJJHB39Obp3FnJOW5J4kTyX53iVuT5JPDfbpsSQ3dLrj\nqprYL/r/YMp/Ab8LbAK+C+xatuZ9wKcHl/cBX57kTLP61XEv/gh40eDye1vei8G6q4GHgaNAb9Zz\nz/D3xU7gUeC3B9dfPuu5Z7gXh4D3Di7vAp6Y9dwT2os/BG4AvneJ228FvgYEuAn4Tpf7nfQz/BuB\nxao6VVXPAfcBe5et2Qt8fnD5AeDmJJnwXLOw4l5U1UNV9ezg6lH6/37wetTl9wXAR4GPAz+b5nBT\n1mUv3g0crKpnAKrqqSnPOC1d9qKAlwwuXwP8cIrzTU1VPUz/Xw+8lL3AvdV3FHhpklesdL+TDv4W\n4PTQ9aXBsYuuqarzwDngZROeaxa67MWwO+j/Db4erbgXg29Rt1XVg9McbAa6/L64DrguybeSHE2y\ne2rTTVeXvfgIcHuSJfr/Ct/7pzPamnO5PQFm+0lbXUKS24Ee8MZZzzILSV4AfBJ414xHWSs20n9Z\n5030v+t7OMnrquqnM51qNm4DPldVf5/kD4AvJHltVf3vrAe7Ekz6Gf4ZYNvQ9a2DYxddk2Qj/W/T\nnp7wXLPQZS9I8mbgw8Ceqvr5lGabtpX24mrgtcA3kzxB/zXK+XV64rbL74slYL6qflFVPwC+T/8v\ngPWmy17cAdwPUFXfBq6i/3N2WtOpJ8tNOvjHgJ1Jrk2yif5J2flla+aBdw4uvw34Rg3OSqwzK+5F\nkuuBz9CP/Xp9nRZW2IuqOldVm6tqR1XtoH8+Y09VjfwzRNawLn9Gvkr/2T1JNtN/iefUNIecki57\n8SRwM0CS19AP/tmpTrk2zAPvGLxb5ybgXFX9aKUvmuhLOlV1PsmdwBH6Z+DvqarjSe4GFqpqHvh3\n+t+WLdI/SbFvkjPNSse9+ATwYuArg/PWT1bVnpkNPSEd96IJHffiCPAnSU4AvwQ+VFXr7rvgjnvx\nQeCzSf6S/gncd63HJ4hJvkT/L/nNg/MVfwP8FkBVfZr++YtbgUXgWeDPO93vOtwrSdJF+ElbSWqE\nwZekRhh8SWqEwZekRhh8SWqEwZekRhh8SWqEwZekRvwf3Wakr5hG2GcAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiFWYY4Z1B2D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ADD START\n",
        "reshaped_y = train_y.reshape((train_y.shape[0],1))\n",
        "train_y = np.append(reshaped_y, reshaped_y, axis=1)\n",
        "train_y[:,1] = 1-train_y[:,0]\n",
        "# ADD END"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yBDVshEyMxb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3240a046-5764-4f82-c9bb-c42dfb07a378"
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "\n",
        "model = keras.Sequential()\n",
        "model.add(Dense(10, activation='relu', input_shape=(1,)))\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(10, activation='relu'))\n",
        "# model.add(Dense(1))\n",
        "model.add(Dense(2))\n",
        "\n",
        "model.compile(optimizer=\"SGD\", loss=\"mse\")\n",
        "model.fit(train_x, train_y, epochs=100, verbose=1, batch_size=32, validation_split=0.1)\n",
        "\n",
        "x_ = np.arange(all_low, all_high, 0.01)\n",
        "y_ = model.predict(x_)\n",
        "plt.scatter(x_, y_[:,0])"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 18000 samples, validate on 2000 samples\n",
            "Epoch 1/100\n",
            "18000/18000 [==============================] - 1s 50us/sample - loss: 0.2551 - val_loss: 0.2466\n",
            "Epoch 2/100\n",
            "18000/18000 [==============================] - 1s 35us/sample - loss: 0.2430 - val_loss: 0.2389\n",
            "Epoch 3/100\n",
            "18000/18000 [==============================] - 1s 34us/sample - loss: 0.2261 - val_loss: 0.2118\n",
            "Epoch 4/100\n",
            "18000/18000 [==============================] - 1s 36us/sample - loss: 0.1948 - val_loss: 0.1705\n",
            "Epoch 5/100\n",
            "18000/18000 [==============================] - 1s 35us/sample - loss: 0.1432 - val_loss: 0.1106\n",
            "Epoch 6/100\n",
            "18000/18000 [==============================] - 1s 36us/sample - loss: 0.0931 - val_loss: 0.0761\n",
            "Epoch 7/100\n",
            "18000/18000 [==============================] - 1s 36us/sample - loss: 0.0739 - val_loss: 0.0671\n",
            "Epoch 8/100\n",
            "18000/18000 [==============================] - 1s 36us/sample - loss: 0.0631 - val_loss: 0.0553\n",
            "Epoch 9/100\n",
            "18000/18000 [==============================] - 1s 35us/sample - loss: 0.0558 - val_loss: 0.0507\n",
            "Epoch 10/100\n",
            "18000/18000 [==============================] - 1s 35us/sample - loss: 0.0520 - val_loss: 0.0494\n",
            "Epoch 11/100\n",
            "18000/18000 [==============================] - 1s 36us/sample - loss: 0.0492 - val_loss: 0.0451\n",
            "Epoch 12/100\n",
            "18000/18000 [==============================] - 1s 36us/sample - loss: 0.0468 - val_loss: 0.0435\n",
            "Epoch 13/100\n",
            "18000/18000 [==============================] - 1s 36us/sample - loss: 0.0446 - val_loss: 0.0407\n",
            "Epoch 14/100\n",
            "18000/18000 [==============================] - 1s 36us/sample - loss: 0.0426 - val_loss: 0.0388\n",
            "Epoch 15/100\n",
            "18000/18000 [==============================] - 1s 36us/sample - loss: 0.0407 - val_loss: 0.0374\n",
            "Epoch 16/100\n",
            "18000/18000 [==============================] - 1s 35us/sample - loss: 0.0389 - val_loss: 0.0355\n",
            "Epoch 17/100\n",
            "18000/18000 [==============================] - 1s 35us/sample - loss: 0.0372 - val_loss: 0.0339\n",
            "Epoch 18/100\n",
            "18000/18000 [==============================] - 1s 35us/sample - loss: 0.0355 - val_loss: 0.0323\n",
            "Epoch 19/100\n",
            "18000/18000 [==============================] - 1s 35us/sample - loss: 0.0338 - val_loss: 0.0307\n",
            "Epoch 20/100\n",
            "18000/18000 [==============================] - 1s 34us/sample - loss: 0.0321 - val_loss: 0.0297\n",
            "Epoch 21/100\n",
            "18000/18000 [==============================] - 1s 36us/sample - loss: 0.0306 - val_loss: 0.0279\n",
            "Epoch 22/100\n",
            "18000/18000 [==============================] - 1s 36us/sample - loss: 0.0290 - val_loss: 0.0262\n",
            "Epoch 23/100\n",
            "18000/18000 [==============================] - 1s 37us/sample - loss: 0.0275 - val_loss: 0.0249\n",
            "Epoch 24/100\n",
            "18000/18000 [==============================] - 1s 38us/sample - loss: 0.0261 - val_loss: 0.0236\n",
            "Epoch 25/100\n",
            "18000/18000 [==============================] - 1s 35us/sample - loss: 0.0246 - val_loss: 0.0227\n",
            "Epoch 26/100\n",
            "18000/18000 [==============================] - 1s 37us/sample - loss: 0.0234 - val_loss: 0.0212\n",
            "Epoch 27/100\n",
            "18000/18000 [==============================] - 1s 34us/sample - loss: 0.0222 - val_loss: 0.0203\n",
            "Epoch 28/100\n",
            "18000/18000 [==============================] - 1s 35us/sample - loss: 0.0211 - val_loss: 0.0192\n",
            "Epoch 29/100\n",
            "18000/18000 [==============================] - 1s 35us/sample - loss: 0.0201 - val_loss: 0.0182\n",
            "Epoch 30/100\n",
            "18000/18000 [==============================] - 1s 35us/sample - loss: 0.0192 - val_loss: 0.0181\n",
            "Epoch 31/100\n",
            "18000/18000 [==============================] - 1s 35us/sample - loss: 0.0184 - val_loss: 0.0175\n",
            "Epoch 32/100\n",
            "18000/18000 [==============================] - 1s 35us/sample - loss: 0.0176 - val_loss: 0.0165\n",
            "Epoch 33/100\n",
            "18000/18000 [==============================] - 1s 36us/sample - loss: 0.0170 - val_loss: 0.0155\n",
            "Epoch 34/100\n",
            "18000/18000 [==============================] - 1s 35us/sample - loss: 0.0163 - val_loss: 0.0155\n",
            "Epoch 35/100\n",
            "18000/18000 [==============================] - 1s 35us/sample - loss: 0.0157 - val_loss: 0.0150\n",
            "Epoch 36/100\n",
            "18000/18000 [==============================] - 1s 36us/sample - loss: 0.0152 - val_loss: 0.0153\n",
            "Epoch 37/100\n",
            "18000/18000 [==============================] - 1s 35us/sample - loss: 0.0147 - val_loss: 0.0143\n",
            "Epoch 38/100\n",
            "18000/18000 [==============================] - 1s 36us/sample - loss: 0.0143 - val_loss: 0.0136\n",
            "Epoch 39/100\n",
            "18000/18000 [==============================] - 1s 37us/sample - loss: 0.0138 - val_loss: 0.0129\n",
            "Epoch 40/100\n",
            "18000/18000 [==============================] - 1s 37us/sample - loss: 0.0134 - val_loss: 0.0129\n",
            "Epoch 41/100\n",
            "18000/18000 [==============================] - 1s 36us/sample - loss: 0.0131 - val_loss: 0.0121\n",
            "Epoch 42/100\n",
            "18000/18000 [==============================] - 1s 37us/sample - loss: 0.0127 - val_loss: 0.0121\n",
            "Epoch 43/100\n",
            "18000/18000 [==============================] - 1s 35us/sample - loss: 0.0124 - val_loss: 0.0117\n",
            "Epoch 44/100\n",
            "18000/18000 [==============================] - 1s 35us/sample - loss: 0.0120 - val_loss: 0.0113\n",
            "Epoch 45/100\n",
            "18000/18000 [==============================] - 1s 35us/sample - loss: 0.0118 - val_loss: 0.0121\n",
            "Epoch 46/100\n",
            "18000/18000 [==============================] - 1s 34us/sample - loss: 0.0115 - val_loss: 0.0109\n",
            "Epoch 47/100\n",
            "18000/18000 [==============================] - 1s 35us/sample - loss: 0.0112 - val_loss: 0.0105\n",
            "Epoch 48/100\n",
            "18000/18000 [==============================] - 1s 38us/sample - loss: 0.0109 - val_loss: 0.0107\n",
            "Epoch 49/100\n",
            "18000/18000 [==============================] - 1s 37us/sample - loss: 0.0108 - val_loss: 0.0101\n",
            "Epoch 50/100\n",
            "18000/18000 [==============================] - 1s 38us/sample - loss: 0.0106 - val_loss: 0.0102\n",
            "Epoch 51/100\n",
            "18000/18000 [==============================] - 1s 35us/sample - loss: 0.0104 - val_loss: 0.0098\n",
            "Epoch 52/100\n",
            "18000/18000 [==============================] - 1s 35us/sample - loss: 0.0102 - val_loss: 0.0097\n",
            "Epoch 53/100\n",
            "18000/18000 [==============================] - 1s 35us/sample - loss: 0.0099 - val_loss: 0.0094\n",
            "Epoch 54/100\n",
            "18000/18000 [==============================] - 1s 38us/sample - loss: 0.0098 - val_loss: 0.0094\n",
            "Epoch 55/100\n",
            "18000/18000 [==============================] - 1s 36us/sample - loss: 0.0097 - val_loss: 0.0091\n",
            "Epoch 56/100\n",
            "18000/18000 [==============================] - 1s 35us/sample - loss: 0.0095 - val_loss: 0.0095\n",
            "Epoch 57/100\n",
            "18000/18000 [==============================] - 1s 36us/sample - loss: 0.0093 - val_loss: 0.0095\n",
            "Epoch 58/100\n",
            "18000/18000 [==============================] - 1s 35us/sample - loss: 0.0092 - val_loss: 0.0087\n",
            "Epoch 59/100\n",
            "18000/18000 [==============================] - 1s 34us/sample - loss: 0.0090 - val_loss: 0.0088\n",
            "Epoch 60/100\n",
            "18000/18000 [==============================] - 1s 36us/sample - loss: 0.0090 - val_loss: 0.0085\n",
            "Epoch 61/100\n",
            "18000/18000 [==============================] - 1s 35us/sample - loss: 0.0088 - val_loss: 0.0086\n",
            "Epoch 62/100\n",
            "18000/18000 [==============================] - 1s 35us/sample - loss: 0.0088 - val_loss: 0.0089\n",
            "Epoch 63/100\n",
            "18000/18000 [==============================] - 1s 35us/sample - loss: 0.0086 - val_loss: 0.0080\n",
            "Epoch 64/100\n",
            "18000/18000 [==============================] - 1s 34us/sample - loss: 0.0085 - val_loss: 0.0089\n",
            "Epoch 65/100\n",
            "18000/18000 [==============================] - 1s 35us/sample - loss: 0.0084 - val_loss: 0.0090\n",
            "Epoch 66/100\n",
            "18000/18000 [==============================] - 1s 35us/sample - loss: 0.0083 - val_loss: 0.0077\n",
            "Epoch 67/100\n",
            "18000/18000 [==============================] - 1s 35us/sample - loss: 0.0081 - val_loss: 0.0081\n",
            "Epoch 68/100\n",
            "18000/18000 [==============================] - 1s 36us/sample - loss: 0.0081 - val_loss: 0.0080\n",
            "Epoch 69/100\n",
            "18000/18000 [==============================] - 1s 34us/sample - loss: 0.0080 - val_loss: 0.0079\n",
            "Epoch 70/100\n",
            "18000/18000 [==============================] - 1s 38us/sample - loss: 0.0078 - val_loss: 0.0073\n",
            "Epoch 71/100\n",
            "18000/18000 [==============================] - 1s 36us/sample - loss: 0.0078 - val_loss: 0.0075\n",
            "Epoch 72/100\n",
            "18000/18000 [==============================] - 1s 35us/sample - loss: 0.0077 - val_loss: 0.0104\n",
            "Epoch 73/100\n",
            "18000/18000 [==============================] - 1s 36us/sample - loss: 0.0077 - val_loss: 0.0082\n",
            "Epoch 74/100\n",
            "18000/18000 [==============================] - 1s 35us/sample - loss: 0.0075 - val_loss: 0.0071\n",
            "Epoch 75/100\n",
            "18000/18000 [==============================] - 1s 35us/sample - loss: 0.0074 - val_loss: 0.0069\n",
            "Epoch 76/100\n",
            "18000/18000 [==============================] - 1s 35us/sample - loss: 0.0074 - val_loss: 0.0086\n",
            "Epoch 77/100\n",
            "18000/18000 [==============================] - 1s 36us/sample - loss: 0.0073 - val_loss: 0.0072\n",
            "Epoch 78/100\n",
            "18000/18000 [==============================] - 1s 38us/sample - loss: 0.0073 - val_loss: 0.0069\n",
            "Epoch 79/100\n",
            "18000/18000 [==============================] - 1s 36us/sample - loss: 0.0072 - val_loss: 0.0080\n",
            "Epoch 80/100\n",
            "18000/18000 [==============================] - 1s 36us/sample - loss: 0.0072 - val_loss: 0.0076\n",
            "Epoch 81/100\n",
            "18000/18000 [==============================] - 1s 35us/sample - loss: 0.0070 - val_loss: 0.0068\n",
            "Epoch 82/100\n",
            "18000/18000 [==============================] - 1s 36us/sample - loss: 0.0070 - val_loss: 0.0065\n",
            "Epoch 83/100\n",
            "18000/18000 [==============================] - 1s 37us/sample - loss: 0.0070 - val_loss: 0.0066\n",
            "Epoch 84/100\n",
            "18000/18000 [==============================] - 1s 36us/sample - loss: 0.0068 - val_loss: 0.0074\n",
            "Epoch 85/100\n",
            "18000/18000 [==============================] - 1s 35us/sample - loss: 0.0067 - val_loss: 0.0066\n",
            "Epoch 86/100\n",
            "18000/18000 [==============================] - 1s 36us/sample - loss: 0.0068 - val_loss: 0.0077\n",
            "Epoch 87/100\n",
            "18000/18000 [==============================] - 1s 36us/sample - loss: 0.0067 - val_loss: 0.0065\n",
            "Epoch 88/100\n",
            "18000/18000 [==============================] - 1s 35us/sample - loss: 0.0067 - val_loss: 0.0105\n",
            "Epoch 89/100\n",
            "18000/18000 [==============================] - 1s 35us/sample - loss: 0.0065 - val_loss: 0.0080\n",
            "Epoch 90/100\n",
            "18000/18000 [==============================] - 1s 35us/sample - loss: 0.0066 - val_loss: 0.0063\n",
            "Epoch 91/100\n",
            "18000/18000 [==============================] - 1s 35us/sample - loss: 0.0064 - val_loss: 0.0070\n",
            "Epoch 92/100\n",
            "18000/18000 [==============================] - 1s 35us/sample - loss: 0.0063 - val_loss: 0.0063\n",
            "Epoch 93/100\n",
            "18000/18000 [==============================] - 1s 35us/sample - loss: 0.0063 - val_loss: 0.0059\n",
            "Epoch 94/100\n",
            "18000/18000 [==============================] - 1s 35us/sample - loss: 0.0062 - val_loss: 0.0086\n",
            "Epoch 95/100\n",
            "18000/18000 [==============================] - 1s 35us/sample - loss: 0.0062 - val_loss: 0.0059\n",
            "Epoch 96/100\n",
            "18000/18000 [==============================] - 1s 35us/sample - loss: 0.0061 - val_loss: 0.0058\n",
            "Epoch 97/100\n",
            "18000/18000 [==============================] - 1s 34us/sample - loss: 0.0061 - val_loss: 0.0062\n",
            "Epoch 98/100\n",
            "18000/18000 [==============================] - 1s 35us/sample - loss: 0.0062 - val_loss: 0.0073\n",
            "Epoch 99/100\n",
            "18000/18000 [==============================] - 1s 36us/sample - loss: 0.0060 - val_loss: 0.0064\n",
            "Epoch 100/100\n",
            "18000/18000 [==============================] - 1s 36us/sample - loss: 0.0060 - val_loss: 0.0078\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f71a573b6a0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAEmRJREFUeJzt3X9sXWd9x/H3F8cFo5UaESMRJyFF\nSjMiipTO6oqQRhkwp53UhIIgRRUwVUTAiiaBLDVi6lD5o7BoSEPqBtFWMZCgFBRFlgiyNCiqVDUs\nrgwNDTMKpdA4bA2l7j8x1M2+++Nelxvj2Nf2ub8ev19SlHOe++ie7+N7/bnnPOfc48hMJElleVmn\nC5AkVc9wl6QCGe6SVCDDXZIKZLhLUoEMd0kqkOEuSQUy3CWpQIa7JBVoU6c2vHnz5tyxY0enNi9J\nPemxxx77TWYOrdSvY+G+Y8cOJicnO7V5SepJEfHLZvo5LSNJBTLcJalAhrskFchwl6QCGe6SVKAV\nwz0i7o+IZyLiJ5d5PCLiixFxJiIej4jrqi9TkrQazey5fwXYu8zjNwE76/8OAv+6/rIkSeuxYrhn\n5sPAb5fpsg/4atacAAYj4nVVFShJWr0qvsQ0DDzdsH623vbrCp5b6nrHpmY4PDHNudk5rhroJwJm\nL8yvennL4ABjo7vYv2e400NSAdr6DdWIOEht6obt27e3c9PSui0V4s9dmCeAhT8zPzs3/1L/1S7P\nzM5x6OgpAANe61ZFuM8A2xrWt9bb/khmHgGOAIyMjORSfaRushDoM7Nzlw3xKt/Ic/MXOTwxbbhr\n3aq4FHIc+GD9qpkbgOcz0ykZ9bxjUzMcOnqKmdk5oNoQX865+vak9Vhxzz0ivgHcCGyOiLPAPwD9\nAJn5JeA4cDNwBrgA/E2ripXa6fDENHPzF9u+3S2DA23fpsqzYrhn5m0rPJ7A31ZWkdQlOrEHPdDf\nx9jorrZvV+XxG6rSZaxmDzrq/w8O9PPqV/YTa1geHhzg3luvdb5dlejY/dylbjc2uotDR09dMjWz\ncFJ10EsY1eUMd+kyFsJ64fJHQ1y9xHCXlrF/z7Bhrp7knLskFchwl6QCGe6SVCDDXZIKZLhLUoEM\nd0kqkOEuSQUy3CWpQIa7JBXIcJekAhnuklQgw12SCmS4S1KBDHdJKpC3/JW6xLGpGe8dr8oY7lIX\nODY1c8lffZqZnePQ0VMABrzWxGkZqQscnpi+5M/5AczNX+TwxHSHKlKvM9ylLnBudm5V7dJKDHep\nC2wZHFhVu7QSw13qAmOjuxjo77ukbaC/j7HRXR2qSL3OE6pSF1g4aerVMqqK4S51if17hg1zVcZp\nGUkqkOEuSQUy3CWpQIa7JBWoqXCPiL0RMR0RZyLiriUe3x4RD0XEVEQ8HhE3V1+qJKlZK4Z7RPQB\n9wE3AbuB2yJi96Jufw88mJl7gAPAv1RdqCSpec3suV8PnMnMJzPzBeABYN+iPgm8qr58FXCuuhIl\nSavVTLgPA083rJ+ttzX6DHB7RJwFjgOfWOqJIuJgRExGxOT58+fXUK4kqRlVnVC9DfhKZm4Fbga+\nFhF/9NyZeSQzRzJzZGhoqKJNS5IWaybcZ4BtDetb622N7gAeBMjMR4FXAJurKFCStHrNhPtJYGdE\nXB0RV1A7YTq+qM+vgHcARMQbqYW78y6S1CErhntmvgjcCUwAP6V2VcwTEXFPRNxS7/Yp4CMR8WPg\nG8CHMzNbVbQkaXlN3TgsM49TO1Ha2HZ3w/Jp4K3VliZJWiu/oSpJBTLcJalAhrskFchwl6QCGe6S\nVCDDXZIKZLhLUoEMd0kqkOEuSQUy3CWpQIa7JBXIcJekAhnuklQgw12SCmS4S1KBDHdJKpDhLkkF\nMtwlqUCGuyQVyHCXpAIZ7pJUIMNdkgpkuEtSgQx3SSqQ4S5JBTLcJalAhrskFchwl6QCGe6SVKCm\nwj0i9kbEdESciYi7LtPnfRFxOiKeiIivV1umJGk1Nq3UISL6gPuAdwFngZMRMZ6Zpxv67AQOAW/N\nzOci4rWtKliStLJm9tyvB85k5pOZ+QLwALBvUZ+PAPdl5nMAmflMtWVKklajmXAfBp5uWD9bb2t0\nDXBNRDwSESciYm9VBUqSVm/FaZlVPM9O4EZgK/BwRFybmbONnSLiIHAQYPv27RVtWqrWsakZDk9M\nc252ji2DA4yN7mL/nsX7M1J3a2bPfQbY1rC+td7W6CwwnpnzmfkL4GfUwv4SmXkkM0cyc2RoaGit\nNUstc2xqhkNHTzEzO0cCM7NzHDp6imNTi9/yUndrJtxPAjsj4uqIuAI4AIwv6nOM2l47EbGZ2jTN\nkxXWKbXF4Ylp5uYvXtI2N3+RwxPTHapIWpsVwz0zXwTuBCaAnwIPZuYTEXFPRNxS7zYBPBsRp4GH\ngLHMfLZVRUutcm52blXtUrdqas49M48Dxxe13d2wnMAn6/+knrVlcICZJYJ8y+BAB6qR1s5vqEoN\nxkZ3MdDfd0nbQH8fY6O7OlSRtDZVXS0jFWHhqhivllGvM9ylRfbvGTbM1fOclpGkAhnuklQgw12S\nCmS4S1KBDHdJKpBXy0hdyJuXab0Md6nLLNy8bOEeNws3LwMMeDXNaRmpy3jzMlXBcJe6jDcvUxUM\nd6nLXO4mZd68TKthuEtdxpuXqQqeUJW6jDcvUxUMd6kLefMyrZfTMpJUIMNdkgpkuEtSgQx3SSqQ\n4S5JBTLcJalAhrskFchwl6QCGe6SVCDDXZIKZLhLUoEMd0kqkOEuSQVqKtwjYm9ETEfEmYi4a5l+\n74mIjIiR6kqUJK3WiuEeEX3AfcBNwG7gtojYvUS/K4G/A35YdZGSpNVpZs/9euBMZj6ZmS8ADwD7\nluj3WeDzwO8qrE+StAbNhPsw8HTD+tl620si4jpgW2Z+p8LaJElrtO4TqhHxMuALwKea6HswIiYj\nYvL8+fPr3bQk6TKaCfcZYFvD+tZ624IrgTcBP4iIp4AbgPGlTqpm5pHMHMnMkaGhobVXLUlaVjPh\nfhLYGRFXR8QVwAFgfOHBzHw+Mzdn5o7M3AGcAG7JzMmWVCxJWtGK4Z6ZLwJ3AhPAT4EHM/OJiLgn\nIm5pdYGSpNXb1EynzDwOHF/Udvdl+t64/rIkSevhN1QlqUCGuyQVyHCXpAIZ7pJUIMNdkgpkuEtS\ngQx3SSqQ4S5JBTLcJalAhrskFchwl6QCGe6SVCDDXZIKZLhLUoEMd0kqkOEuSQUy3CWpQIa7JBXI\ncJekAhnuklQgw12SCmS4S1KBDHdJKpDhLkkFMtwlqUCGuyQVyHCXpAIZ7pJUIMNdkgpkuEtSgZoK\n94jYGxHTEXEmIu5a4vFPRsTpiHg8Ir4XEa+vvlRJUrNWDPeI6APuA24CdgO3RcTuRd2mgJHMfDPw\nbeAfqy5UktS8ZvbcrwfOZOaTmfkC8ACwr7FDZj6UmRfqqyeArdWWKUlajWbCfRh4umH9bL3tcu4A\nvrvUAxFxMCImI2Ly/PnzzVcpSVqVSk+oRsTtwAhweKnHM/NIZo5k5sjQ0FCVm5YkNdjURJ8ZYFvD\n+tZ62yUi4p3Ap4G3ZebvqylPkrQWzYT7SWBnRFxNLdQPAB9o7BARe4AvA3sz85nKq5Ra7NjUDIcn\npjk3O8eWwQHGRnexf89ys49Sd1sx3DPzxYi4E5gA+oD7M/OJiLgHmMzMcWrTMH8CfCsiAH6Vmbe0\nsG6pMsemZjh09BRz8xcBmJmd49DRUwAGvHpWM3vuZOZx4Piitrsblt9ZcV1S2xyemH4p2BfMzV/k\n8MR0V4S7RxVai6bCXSrZudm5VbW3k0cVWitvP6ANb8vgwKra22m5owppOYa7Nryx0V0M9Pdd0jbQ\n38fY6K4OVfQH3XxUoe5muGvD279nmHtvvZbhwQECGB4c4N5br+2KaY9uPqpQd3POXaIW8N0Q5ouN\nje66ZM4duueoQt3NcJe62MIHjlfLaLUMd6nLdetRhbqbc+6SVCDDXZIKZLhLUoEMd0kqkOEuSQUy\n3CWpQIa7JBXIcJekAhnuklQgw12SCmS4S1KBDHdJKpDhLkkFMtwlqUCGuyQVyHCXpAIZ7pJUIMNd\nkgpkuEtSgQx3SSqQ4S5JBdrU6QKkTjk2NcPhiWnOzc6xZXCAsdFd7N8z3OmyltVY81UD/UTA7IX5\ndS33yti1OpGZK3eK2Av8M9AH/Ftmfm7R4y8Hvgr8GfAs8P7MfGq55xwZGcnJyck1li01b6lAfO7C\nPAE0vvsH+vu499Zruzbkjk3NcOjoKebmL1b+3As/i8EKPzDe/qdDPPTf53vqw7MXRMRjmTmyYr+V\nwj0i+oCfAe8CzgIngdsy83RDn48Db87Mj0bEAeDdmfn+5Z7XcK9eM3t1i3/pqtr769blpUJ8OcOD\nAzxy11+28mVas7d+7vvMzM51uow1q/oDZKMefVQZ7m8BPpOZo/X1QwCZeW9Dn4l6n0cjYhPwP8BQ\nLvPk3R7urTj87aYQ09IC+MXn/rrTZSzp6ru+4+u7jFZ+eHTTh1Cz4d7MnPsw8HTD+lngzy/XJzNf\njIjngdcAv2mu3NVrZfguDsrZufmXttvNy/7ir9+WwYFOl3BZWwYHenrPvdV64fd1ZnaOQ0dPAbT8\nKKOtV8tExMGImIyIyfPnz6/5eRbmHmdm50hqP7znLsxXtgwG5UY00N/H2OiuTpdxWWOjuxjo7+t0\nGVqnufmLHJ6Ybvl2mgn3GWBbw/rWetuSferTMldRO7F6icw8kpkjmTkyNDS0toqBwxPTLTmppI0n\n6v8PDw509clUqO3p3XvrtQwPDhDUph9e/cr+dS3DH34Gap9zbTgCa2Za5iSwMyKuphbiB4APLOoz\nDnwIeBR4L/D95ebb16sdPxiVZan52F48Cbd/z3Dl9bbq8sqFE/czs3OeD1qkHdN/K4Z7fQ79TmCC\n2qWQ92fmExFxDzCZmePAvwNfi4gzwG+pfQC0jHOPl7fSSaWNdrVMr4Z4O7XiA2Oxdp4j63btmv5r\n6jr3VljP1TKtvN63US+cfTfEpN65uq3brpbpOgs/mFa+mAal1DvacfTRa3oy3MEXU5KW443DJKlA\nhrskFchwl6QCGe6SVCDDXZIKZLhLUoEMd0kqkOEuSQXq2O0HIuI88MsKnmozLbxvfBfaaOOFjTfm\njTZe2HhjXs94X5+ZK95Wt2PhXpWImGzmPgul2GjjhY035o02Xth4Y27HeJ2WkaQCGe6SVKASwv1I\npwtos402Xth4Y95o44WNN+aWj7fn59wlSX+shD13SdIiPRPuEbE3IqYj4kxE3LXE4y+PiG/WH/9h\nROxof5XVaWK8n4yI0xHxeER8LyJe34k6q7TSmBv6vSciMiJ6+uqKZsYbEe+rv85PRMTX211jlZp4\nT2+PiIciYqr+vr65E3VWJSLuj4hnIuInl3k8IuKL9Z/H4xFxXaUFZGbX/6P2t1t/DrwBuAL4MbB7\nUZ+PA1+qLx8Avtnpuls83rcDr6wvf6yXx9vsmOv9rgQeBk4AI52uu8Wv8U5gCnh1ff21na67xeM9\nAnysvrwbeKrTda9zzH8BXAf85DKP3wx8l9pf9LwB+GGV2++VPffrgTOZ+WRmvgA8AOxb1Gcf8B/1\n5W8D74iIaGONVVpxvJn5UGZeqK+eALa2ucaqNfMaA3wW+Dzwu3YW1wLNjPcjwH2Z+RxAZj7T5hqr\n1Mx4E3hVffkq4Fwb66tcZj4M/HaZLvuAr2bNCWAwIl5X1fZ7JdyHgacb1s/W25bsk5kvAs8Dr2lL\nddVrZryN7qC2B9DLVhxz/bB1W2Z+p52FtUgzr/E1wDUR8UhEnIiIvW2rrnrNjPczwO0RcRY4Dnyi\nPaV1zGp/z1elZ/+Gqmoi4nZgBHhbp2tppYh4GfAF4MMdLqWdNlGbmrmR2pHZwxFxbWbOdrSq1rkN\n+Epm/lNEvAX4WkS8KTP/r9OF9aJe2XOfAbY1rG+tty3ZJyI2UTuse7Yt1VWvmfESEe8EPg3ckpm/\nb1NtrbLSmK8E3gT8ICKeojZHOd7DJ1WbeY3PAuOZOZ+ZvwB+Ri3se1Ez470DeBAgMx8FXkHtHiyl\naur3fK16JdxPAjsj4uqIuILaCdPxRX3GgQ/Vl98LfD/rZy160IrjjYg9wJepBXsvz8UuWHbMmfl8\nZm7OzB2ZuYPaeYZbMnOyM+WuWzPv6WPU9tqJiM3UpmmebGeRFWpmvL8C3gEQEW+kFu7n21ple40D\nH6xfNXMD8Hxm/rqyZ+/0GeVVnHm+mdqey8+BT9fb7qH2Cw61N8K3gDPAfwFv6HTNLR7vfwL/C/yo\n/m+80zW3esyL+v6AHr5apsnXOKhNRZ0GTgEHOl1zi8e7G3iE2pU0PwL+qtM1r3O83wB+DcxTOwq7\nA/go8NGG1/e++s/jVNXvZ7+hKkkF6pVpGUnSKhjuklQgw12SCmS4S1KBDHdJKpDhLkkFMtwlqUCG\nuyQV6P8BkBRxCcensEUAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzTg8ocJ11NI",
        "colab_type": "text"
      },
      "source": [
        "출력 노드의 값은 0과 1이 서로 상반된다.\n",
        "\n",
        "하지만 이렇게 카테고리 개수 만큼 출력 노드가 있는 경우, 카테고리를 2개 이상으로 해도 처리가 가능해 진다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5MGpN31104d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxWMUkV_0ovc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}